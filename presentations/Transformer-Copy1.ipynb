{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_size, **kwargs):\n",
    "        super(TransformerEmbedding, self).__init__(**kwargs)\n",
    "        self.x_dim = vocab_size\n",
    "        self.y_dim = embedding_size\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.x_dim, self.y_dim), initializer=\"random_normal\", trainable=True)\n",
    "        \n",
    "    def call(self, input_layer, **kwargs):\n",
    "        # Here I've implemented it to only return the final relevant time step for the final projection\n",
    "        if 'projection' in kwargs.keys():\n",
    "            if kwargs['projection'] == True:\n",
    "                return tf.matmul(input_layer, tf.transpose(tf.expand_dims(self.w, axis=0), perm=[0,2,1]))\n",
    "        # do the normal input embedding operation if 'projection' is not in kwargs or equals False\n",
    "        # this sets the current time step for the output\n",
    "        one_hot = tf.keras.backend.one_hot(input_layer, self.x_dim)\n",
    "        return tf.matmul(one_hot, tf.expand_dims(self.w * np.sqrt(512), axis=0))\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\"vocab_size\" : self.x_dim,\n",
    "                 \"embedding_size\" : self.y_dim}\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiheadAttention(keras.layers.Layer):\n",
    "    def __init__(self, h=8, projection_dim=64, mask=False, **kwargs):\n",
    "        super(MultiheadAttention, self).__init__(**kwargs)\n",
    "        self.h = h\n",
    "        self.projection_dim = projection_dim\n",
    "        self.mask = mask\n",
    "        \n",
    "        self.concat = keras.layers.Concatenate(name=self.name + \"_concat\")\n",
    "        self.dropout = keras.layers.Dropout(.1, name=self.name + \"_dropout\")\n",
    "        self.addition = keras.layers.Add(name = self.name + \"_add\")\n",
    "        self.normalize = keras.layers.BatchNormalization(name = self.name + \"_batchnorm\")\n",
    "        \n",
    "    def generate_mask(self, input_tensor):\n",
    "        shape = input_tensor.shape\n",
    "        mask = np.ndarray((shape[1], shape[2]), dtype=np.float32)\n",
    "        for i in range(shape[1]):\n",
    "            for j in range(shape[2]):\n",
    "                if j > i:\n",
    "                    mask[i][j] = np.NINF\n",
    "                else:\n",
    "                    mask[i][j] = 0\n",
    "        mask = tf.convert_to_tensor(mask)\n",
    "        mask = tf.expand_dims(mask, axis=0)\n",
    "        return tf.math.add(input_tensor, mask)\n",
    "        \n",
    "    def _linearly_project(self, queries, keys, values):\n",
    "        projections = []\n",
    "        for i in range(self.h):\n",
    "            proj_dict = {}\n",
    "            proj_dict['queries'] = tf.matmul(queries, self.query_weights[i])\n",
    "            proj_dict['keys'] = tf.matmul(keys, self.key_weights[i])\n",
    "            proj_dict['values'] = tf.matmul(values, self.value_weights[i])\n",
    "            projections.append(proj_dict)\n",
    "        return projections\n",
    "    \n",
    "    def _linearly_project_concat(self, input_):\n",
    "        return tf.matmul(input_, self.w_o)\n",
    "    \n",
    "    def _ScaledDotProduct_step(self, queries, keys, values):\n",
    "        step_1 = tf.matmul(queries, tf.transpose(keys, perm=[0,2,1]))\n",
    "        step_2 = tf.math.scalar_mul(1/np.sqrt(self.projection_dim), step_1)\n",
    "        #print('Step 2 shape:', step_2.shape)\n",
    "        # the output of step 2 is essentially oriented as all positions (32 x 32)\n",
    "        if self.mask:\n",
    "            # this fails: the documentation says ragged tensor would work to preserve dimensionality\n",
    "            # but neither step_2 nor step_4 are ragged tensors\n",
    "            step_3 = self.generate_mask(step_2)\n",
    "            print(step_3.shape)\n",
    "        else:\n",
    "            step_3 = step_2\n",
    "        step_4 = tf.nn.softmax(step_3)\n",
    "        #print('Step 4 shape:', step_4.shape)\n",
    "        step_5 = tf.matmul(step_4, values)\n",
    "        # step 5 returns the shape to 32 x 64\n",
    "        #print('Step 5 shape:', step_5.shape)\n",
    "        return step_5\n",
    "    \n",
    "    def _ScaledDotProduct(self, projections):\n",
    "        results = []\n",
    "        for i in range(self.h):\n",
    "            results.append(self._ScaledDotProduct_step(\n",
    "                projections[i]['queries'],\n",
    "                projections[i]['keys'],\n",
    "                projections[i]['values'],\n",
    "            ))\n",
    "        return results\n",
    "    \n",
    "    def build(self, input_shape): # what to do with input_shape if 3 inputs?\n",
    "        print(input_shape)\n",
    "        self.query_weights = []\n",
    "        self.key_weights = []\n",
    "        self.value_weights = []\n",
    "        # successfully completes cycle\n",
    "        for i in range(self.h):\n",
    "            self.query_weights.append(self.add_weight(\n",
    "                shape=(input_shape[0][-1], self.projection_dim),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "                name='queries:' + str(i),\n",
    "            ))\n",
    "            self.key_weights.append(self.add_weight(\n",
    "                shape=(input_shape[0][-1], self.projection_dim),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "                name='keys:' + str(i),\n",
    "            ))\n",
    "            self.value_weights.append(self.add_weight(\n",
    "                shape=(input_shape[0][-1], self.projection_dim),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "                name='values:' + str(i),\n",
    "            ))\n",
    "        self.w_o = self.add_weight(\n",
    "            shape=(self.h * self.projection_dim, input_shape[0][-1]),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        print('Build complete.')\n",
    "        \n",
    "    def call(self, input_set):\n",
    "        '''keys and values are assumed to be the same'''\n",
    "        print('Calling MultiheadAttention.')\n",
    "        queries, keys, values = input_set\n",
    "        projections = self._linearly_project(queries, keys, values) \n",
    "        scaled_attention = self._ScaledDotProduct(projections)\n",
    "        concat = self.concat(scaled_attention)\n",
    "        projected = self._linearly_project_concat(concat)\n",
    "        dropout = self.dropout(projected)\n",
    "        addition = self.addition([queries, dropout])\n",
    "        normalize = self.normalize(addition)\n",
    "        return normalize\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        config[\"h\"] = self.h\n",
    "        config[\"projection_dim\"] = self.projection_dim\n",
    "        config[\"mask\"] = self.mask\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _positional_encoding(input_tensor, output_dim=512):\n",
    "    print('Calling _positional_encoding.')\n",
    "    num_pos = input_tensor.shape[1]\n",
    "    encoding = np.zeros((num_pos, output_dim))\n",
    "    for pos in range(num_pos):\n",
    "        for i in range(int(output_dim / 2)):\n",
    "            encoding[pos, 2*i] = np.sin(pos/10000**(2*i/output_dim))\n",
    "            encoding[pos, 2*i+1] = np.cos(pos/10000**(2*i/output_dim))\n",
    "    encoding = tf.convert_to_tensor(encoding, dtype=tf.float32)\n",
    "    encoding = tf.expand_dims(encoding, axis=0)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardUnit(keras.layers.Layer):\n",
    "    def __init__(self, model_dim=512, **kwargs):\n",
    "        super(FeedforwardUnit, self).__init__(**kwargs)\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.ff1 = keras.layers.Dense(2048, activation='relu', name=self.name+\"_ff1\")\n",
    "        self.ff2 = keras.layers.Dense(self.model_dim, activation=None, name=self.name+\"_ff2\")\n",
    "        self.dropout = keras.layers.Dropout(0.1, name=self.name+\"_dropout\")\n",
    "        self.addition = keras.layers.Add(name=self.name+\"_add\")\n",
    "        self.normalize = keras.layers.BatchNormalization(name=self.name+\"_batchnorm\")\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        print('Calling FeedforwardUnit.')\n",
    "        ff1 = self.ff1(input_tensor)\n",
    "        ff2 = self.ff2(ff1)\n",
    "        dropout_ff = self.dropout(ff2)\n",
    "        added_ff = self.addition([input_tensor, dropout_ff])\n",
    "        normalize_ff = self.normalize(added_ff)\n",
    "        return normalize_ff\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"model_dim\" : self.model_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NotImplementedError: Layer EncoderUnit has arguments in `__init__` and therefore must override `get_config`.\n",
    "class EncoderUnit(keras.layers.Layer):\n",
    "    def __init__(self, h=8, projection_dim=64, model_dim=512, mask=False, **kwargs):\n",
    "        super(EncoderUnit, self).__init__(**kwargs)\n",
    "        self.h = h\n",
    "        self.projection_dim = projection_dim\n",
    "        self.model_dim = model_dim\n",
    "        self.mask = mask\n",
    "        \n",
    "        self.ma = MultiheadAttention(h=self.h, \n",
    "                                projection_dim=self.projection_dim, \n",
    "                                mask=self.mask, name=self.name+\"_MultiheadAttention\")\n",
    "        self.ff = FeedforwardUnit(name=self.name+\"_FeedforwardUnit\")\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        print('Calling EncoderUnit.')\n",
    "        ma = self.ma([input_tensor, input_tensor, input_tensor])\n",
    "        ff = self.ff(ma)\n",
    "        return ff\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        config[\"h\"] = self.h\n",
    "        config[\"projection_dim\"] = self.projection_dim\n",
    "        config[\"model_dim\"] = self.model_dim\n",
    "        config[\"mask\"] = self.mask\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderUnit(keras.layers.Layer):\n",
    "    def __init__(self, h=8, projection_dim=64, model_dim=512, mask=True, **kwargs):\n",
    "        super(DecoderUnit, self).__init__(**kwargs)\n",
    "        self.h = h\n",
    "        self.projection_dim = projection_dim\n",
    "        self.model_dim = model_dim\n",
    "        self.mask = mask\n",
    "        \n",
    "        self.mma = MultiheadAttention(h=self.h,\n",
    "                               projection_dim=self.projection_dim,\n",
    "                               mask=self.mask,\n",
    "                               name=self.name+\"_MultiheadAttention_1\")\n",
    "        self.ma = MultiheadAttention(h=self.h,\n",
    "                               projection_dim=self.projection_dim,\n",
    "                               mask=False,\n",
    "                               name=self.name+\"_MultiheadAttention_2\")\n",
    "        self.ff = FeedforwardUnit(name=self.name+\"_FeedforwardUnit\")\n",
    "        \n",
    "    def call(self, input_set):\n",
    "        print('Calling DecoderUnit.')\n",
    "        encoding = input_set[0]\n",
    "        encoder_stack_output = input_set[1]\n",
    "        mma = self.mma([encoding, encoding, encoding])\n",
    "        ma = self.ma([mma, encoder_stack_output, encoder_stack_output])\n",
    "        ff = self.ff(ma)\n",
    "        return ff\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        config[\"h\"] = self.h\n",
    "        config[\"projection_dim\"] = self.projection_dim\n",
    "        config[\"model_dim\"] = self.model_dim\n",
    "        config[\"mask\"] = self.mask\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, external_weights, **kwargs):\n",
    "        super(Linear, self).__init__(**kwargs)\n",
    "        self.external_weights = tf.convert_to_tensor(external_weights)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # this is highly problematic:\n",
    "        # this wasn't added as a weight before, and now it's being added wrong because it needs to be\n",
    "        # a tensor passed in\n",
    "        # I might want to undo these changes first with trainable_weights, then figure out the name issue\n",
    "        #   then return to this problem\n",
    "        self.w = self.external_weights\n",
    "        \n",
    "    def call(self, input_layer):\n",
    "        print('Calling Linear.')\n",
    "        return tf.matmul(input_layer, tf.transpose(tf.expand_dims(tf.math.scalar_mul((1/np.sqrt(512)), self.w), axis=0), perm=[0,2,1]))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"external_weights\": self.external_weights.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser(os.path.join('~',\n",
    "                                        'python_workspace',\n",
    "                                        'processed_data')))\n",
    "filenames = [f for f in os.listdir('.') if 'preprocess.txt' in f and \\\n",
    "            'text' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames += ['relative_examples.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 5\n",
    "data = []\n",
    "for file in filenames:\n",
    "    with open(file, 'r') as f:\n",
    "        in_data = f.readlines()\n",
    "        for i in range(0, len(in_data) - stride, 1):\n",
    "            segment = in_data[i : i + stride]\n",
    "            data.append([line.strip().split('\\t') for line in segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "input_data = []\n",
    "output_data = []\n",
    "for item in data:\n",
    "    for line in item:\n",
    "        try:\n",
    "            input_data.append(line[0])\n",
    "            output_data.append(line[1])\n",
    "        except IndexError:\n",
    "            continue\n",
    "    if input_data[-1][-1] == '&':\n",
    "        input_data = input_data[:-1]\n",
    "        output_data = output_data[:-1]\n",
    "    input_item = ' '.join(input_data)\n",
    "    input_item = re.sub('& ', ' ', input_item)\n",
    "    input_item = re.sub('% ', '', input_item)\n",
    "    input_item = re.sub('%$', '', input_item)\n",
    "    input_item = re.sub(' ,', '', input_item)\n",
    "    output_item = ' '.join(output_data)\n",
    "    output_item = re.sub(' ,', '', output_item)\n",
    "    dataset.append((input_item, output_item))\n",
    "    input_data = []\n",
    "    output_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete_set = set(''.join([item[0] for item in dataset])).union(' '.join([item[1] for item in dataset]).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_vocab = {k: i for (i, k) in enumerate(complete_set)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inv_total_vocab = {i: k for (k, i) in total_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_vocab['<pad>'] = max(total_vocab.values()) + 1\n",
    "inv_total_vocab[total_vocab['<pad>']] = '<pad>'\n",
    "total_vocab['<start>'] = max(total_vocab.values()) + 1\n",
    "inv_total_vocab[total_vocab['<start>']] = '<start>'\n",
    "#total_vocab['<end>'] = max(total_vocab.values()) + 1\n",
    "#inv_total_vocab[total_vocab['<end>']] = '<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = pickle.load(open('total_vocab_2.pkl', 'rb'))\n",
    "inv_total_vocab = pickle.load(open('inv_total_vocab_2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.dump(total_vocab, open('total_vocab_2.pkl', 'wb'))\n",
    "pickle.dump(inv_total_vocab, open('inv_total_vocab_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for item in dataset:\n",
    "    try:\n",
    "        data_dict[len(item[0])].append(item)\n",
    "    except KeyError:\n",
    "        data_dict[len(item[0])] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_int(sent, Tx, human_vocab):\n",
    "    input_l = list(sent)\n",
    "    input_n = np.array([[human_vocab[c] for c in input_l]])\n",
    "    input_pad = pad_sequences(input_n, maxlen=Tx, dtype='int32',\n",
    "                  padding='post', value=total_vocab['<pad>'])\n",
    "    input_pad = np.asarray([value for line in input_pad for value in line]).reshape(len(input_n), Tx)\n",
    "    return input_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, total_vocab, inv_total_vocab):\n",
    "    \n",
    "    input_pre, output_pre = zip(*dataset)\n",
    "    \n",
    "    input_l = [list(l) for l in input_pre]\n",
    "    output_w = [l.split() for l in output_pre]\n",
    "    \n",
    "    max_input = max([len(l) for l in input_l])\n",
    "    max_output = max([len(l) for l in output_w])\n",
    "    \n",
    "    input_n = np.array([[total_vocab[c] for c in line] for line in input_l])\n",
    "    \n",
    "    print(type(input_n))\n",
    "    if '<pad>' not in total_vocab.keys():\n",
    "        total_vocab['<pad>'] = max(total_vocab.values()) + 1\n",
    "        inv_total_vocab[total_vocab['<pad>']] = '<pad>'\n",
    "    if '<start>' not in total_vocab.keys():\n",
    "        total_vocab['<start>'] = max(total_vocab.values()) + 1\n",
    "        inv_total_vocab[total_vocab['<start>']] = '<start>'\n",
    "    if '<end>' not in total_vocab.keys():\n",
    "        total_vocab['<end>'] = max(total_vocab.values()) + 1\n",
    "        inv_total_vocab[total_vocab['<end>']] = '<end>'\n",
    "        \n",
    "    output_n = np.array([[total_vocab['<start>']] + \\\n",
    "                      [total_vocab[c] for c in line] + \\\n",
    "                      [total_vocab['<end>']] for line in output_w])\n",
    "    max_output += 2 # adjusts for <start> and <end> tokens\n",
    "        \n",
    "    input_positionalized = []\n",
    "    output_in_positionalized = []\n",
    "    output_out_positionalized = []\n",
    "    \n",
    "    for i, line in enumerate(output_n):\n",
    "        for j in range(1,len(line)):\n",
    "            input_positionalized.append(input_n[i])\n",
    "            output_in_positionalized.append(line[:j])\n",
    "            output_out_positionalized.append(line[:j+1])\n",
    "    \n",
    "    # now pad\n",
    "    input_pad = pad_sequences(input_positionalized, maxlen=max_input, dtype='int32',\n",
    "                  padding='post', value=total_vocab['<pad>'])\n",
    "    output_in_pad = pad_sequences(output_in_positionalized, maxlen=max_output, dtype='int32',\n",
    "                  padding='post', value=total_vocab['<pad>'])\n",
    "    output_out_pad = pad_sequences(output_out_positionalized, maxlen=max_output, dtype='int32',\n",
    "                  padding='post', value=total_vocab['<pad>'])\n",
    "\n",
    "    \n",
    "\n",
    "    # these convert the data into numpy arrays with depth\n",
    "    input_pad = np.asarray([value for line in input_pad for value in line]).reshape(len(input_positionalized), max_input)\n",
    "    output_in_pad = np.asarray([value for line in output_in_pad for value in line]).reshape(len(output_in_positionalized), max_output)\n",
    "    output_out_pad = np.asarray([value for line in output_out_pad for value in line]).reshape(len(output_out_positionalized), max_output)\n",
    "    \n",
    "    output_oh = np.zeros((len(output_out_positionalized), max_output, len(total_vocab)))\n",
    "    \n",
    "    # assign 1 values\n",
    "    for i, line in enumerate(output_out_pad):\n",
    "        for j, value in enumerate(line):\n",
    "            output_oh[i,j,value] = 1\n",
    "    \n",
    "    return input_pad, output_in_pad, output_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, Y_in, Yoh = preprocess_data(dataset, total_vocab, inv_total_vocab)\n",
    "Tx = X.shape[1]\n",
    "Ty_in = Y_in.shape[1]\n",
    "Ty = Yoh.shape[1]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y_in.shape)\n",
    "print(Yoh.shape)\n",
    "\n",
    "X_train, X_test, Y_in_train, Y_in_test, Yoh_train, Yoh_test = \\\n",
    "    train_test_split(X, Y_in, Yoh, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.dump(X_train, open('X_train_2.pkl', 'wb'))\n",
    "pickle.dump(X_test, open('X_test_2.pkl', 'wb'))\n",
    "pickle.dump(Y_in_train, open('Y_in_train_2.pkl', 'wb'))\n",
    "pickle.dump(Y_in_test, open('Y_in_test_2.pkl', 'wb'))\n",
    "pickle.dump(Yoh_train, open('Yoh_train_2.pkl', 'wb'))\n",
    "pickle.dump(Yoh_test, open('Yoh_test_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open('X_train_2.pkl', 'rb'))\n",
    "X_test = pickle.load(open('X_test_2.pkl', 'rb'))\n",
    "#X_decoder_train = pickle.load(open('X_decoder_train.pkl', 'rb'))\n",
    "#X_decoder_test = pickle.load(open('X_decoder_test.pkl', 'rb'))\n",
    "Y_in_train = pickle.load(open('Y_in_train_2.pkl', 'rb'))\n",
    "Y_in_test = pickle.load(open('Y_in_test_2.pkl', 'rb'))\n",
    "Yoh_train = pickle.load(open('Yoh_train_2.pkl', 'rb'))\n",
    "Yoh_test = pickle.load(open('Yoh_test_2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_X = X_train.shape[1] # normalized length of all members of batch\n",
    "sequence_length_Y = Yoh_train.shape[1]\n",
    "vocab_size = len(total_vocab) # vocab_size would be the total number of possible byte-pair encodings\n",
    "embedding_size = 512 # I should probably adjust this\n",
    "# I'm going to do padding and see what happens\n",
    "# for input and output language issues, I'm going to include both input and output language content into\n",
    "#    a single embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed_layer = keras.layers.Embedding(vocab_size, embedding_size, weights=[np.sqrt(512) * embed_weights], name=\"input_embedding\")\n",
    "embed_layer = TransformerEmbedding(vocab_size, embedding_size, name=\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling _positional_encoding.\n"
     ]
    }
   ],
   "source": [
    "x_i = keras.layers.Input(shape=(sequence_length_X,), dtype=\"int32\", name=\"encoder_input\")\n",
    "embed_i = embed_layer(x_i)\n",
    "pe_i_layer = keras.layers.Lambda(_positional_encoding, name=\"encoder_input_lambda\")\n",
    "pe_i = pe_i_layer(x_i)\n",
    "added_i = keras.layers.Add(name=\"encoder_input_add\")([embed_i, pe_i])\n",
    "dropout_intro_i = keras.layers.Dropout(0.1, name=\"encoder_input_dropout\")(added_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling EncoderUnit.\n",
      "[TensorShape([None, 57, 512]), TensorShape([None, 57, 512]), TensorShape([None, 57, 512])]\n",
      "Build complete.\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n"
     ]
    }
   ],
   "source": [
    "ee_unit = EncoderUnit(name=\"EncoderUnit\")\n",
    "ee = ee_unit(dropout_intro_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling _positional_encoding.\n"
     ]
    }
   ],
   "source": [
    "x_o = keras.layers.Input(shape=(sequence_length_Y,), dtype=\"int32\", name=\"decoder_input\")\n",
    "embed_o = embed_layer(x_o)\n",
    "pe_o_layer = keras.layers.Lambda(_positional_encoding, name=\"decoder_input_lambda\")\n",
    "pe_o = pe_o_layer(x_o)\n",
    "added_o = keras.layers.Add(name=\"decoder_input_add\")([embed_o, pe_o])\n",
    "dropout_intro_o = keras.layers.Dropout(0.1, name=\"decoder_input_dropout\")(added_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling DecoderUnit.\n",
      "[TensorShape([None, 7, 512]), TensorShape([None, 7, 512]), TensorShape([None, 7, 512])]\n",
      "Build complete.\n",
      "Calling MultiheadAttention.\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "[TensorShape([None, 7, 512]), TensorShape([None, 57, 512]), TensorShape([None, 57, 512])]\n",
      "Build complete.\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n"
     ]
    }
   ],
   "source": [
    "du = DecoderUnit(name=\"DecoderUnit\")([dropout_intro_o, ee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_3 = keras.layers.Lambda(_embed_to_linear)(embed_weights)\n",
    "#linear_layer = Linear(weights=lambda_3) # the problem is actually here\n",
    "#linear_layer = Linear(embed_layer.weights[0], name=\"LinearLayer\")\n",
    "#linear = linear_layer(du)\n",
    "linear = embed_layer(du, projection=True)\n",
    "softmax = keras.layers.Activation('softmax', name=\"FinalActivation\")(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[x_i, x_o], outputs=softmax, name='transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def decay(epoch):\n",
    "    epoch_adj = epoch + 73\n",
    "    initial_rate = 512**-0.5\n",
    "    warmup_steps = 4000\n",
    "    lrate = initial_rate * min(epoch_adj**-0.5, epoch_adj * warmup_steps ** -1.5)\n",
    "    return lrate\n",
    "\n",
    "lrate = keras.callbacks.LearningRateScheduler(decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.getcwd(),\n",
    "    save_weights_only=False,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=512**-0.5, beta_1=0.9, beta_2=0.98, epsilon=1e-09)\n",
    "cc = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss=cc, metrics=['accuracy'])\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (TransformerEmbedding multiple             299008      encoder_input[0][0]              \n",
      "                                                                 decoder_input[0][0]              \n",
      "                                                                 DecoderUnit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_lambda (Lambda)   (1, 57, 512)         0           encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_lambda (Lambda)   (1, 7, 512)          0           decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_add (Add)         (None, 57, 512)      0           embedding[0][0]                  \n",
      "                                                                 encoder_input_lambda[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_add (Add)         (None, 7, 512)       0           embedding[1][0]                  \n",
      "                                                                 decoder_input_lambda[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input_dropout (Dropout) (None, 57, 512)      0           encoder_input_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_dropout (Dropout) (None, 7, 512)       0           decoder_input_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "EncoderUnit (EncoderUnit)       (None, 57, 512)      3152384     encoder_input_dropout[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "DecoderUnit (DecoderUnit)       (None, 7, 512)       4203008     decoder_input_dropout[0][0]      \n",
      "                                                                 EncoderUnit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "FinalActivation (Activation)    (None, 7, 584)       0           embedding[2][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,654,400\n",
      "Trainable params: 7,649,280\n",
      "Non-trainable params: 5,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# I probably need to just download the weights for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1.275257518417849e-05.\n",
      "Epoch 1/20\n",
      "Calling _positional_encoding.\n",
      "Calling _positional_encoding.\n",
      "Calling EncoderUnit.\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n",
      "Calling DecoderUnit.\n",
      "Calling MultiheadAttention.\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n",
      "Calling _positional_encoding.\n",
      "Calling _positional_encoding.\n",
      "Calling EncoderUnit.\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n",
      "Calling DecoderUnit.\n",
      "Calling MultiheadAttention.\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n",
      "536/536 [==============================] - 1667s 3s/step - loss: 56.2766 - accuracy: 0.9422 - lr: 1.2753e-05\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.2927267994920662e-05.\n",
      "Epoch 2/20\n",
      "536/536 [==============================] - 1660s 3s/step - loss: 56.2725 - accuracy: 0.9436 - lr: 1.2927e-05\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1.3101960805662831e-05.\n",
      "Epoch 3/20\n",
      "536/536 [==============================] - 1664s 3s/step - loss: 56.2675 - accuracy: 0.9453 - lr: 1.3102e-05\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 1.3276653616405003e-05.\n",
      "Epoch 4/20\n",
      "536/536 [==============================] - 1728s 3s/step - loss: 56.2632 - accuracy: 0.9471 - lr: 1.3277e-05\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 1.3451346427147174e-05.\n",
      "Epoch 5/20\n",
      "536/536 [==============================] - 1665s 3s/step - loss: 56.2596 - accuracy: 0.9473 - lr: 1.3451e-05\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 1.3626039237889345e-05.\n",
      "Epoch 6/20\n",
      "536/536 [==============================] - 1663s 3s/step - loss: 56.2552 - accuracy: 0.9485 - lr: 1.3626e-05\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 1.3800732048631515e-05.\n",
      "Epoch 7/20\n",
      "536/536 [==============================] - 1663s 3s/step - loss: 56.2518 - accuracy: 0.9499 - lr: 1.3801e-05\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 1.3975424859373686e-05.\n",
      "Epoch 8/20\n",
      "536/536 [==============================] - 1669s 3s/step - loss: 56.2476 - accuracy: 0.9511 - lr: 1.3975e-05\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 1.4150117670115857e-05.\n",
      "Epoch 9/20\n",
      "536/536 [==============================] - 1677s 3s/step - loss: 56.2443 - accuracy: 0.9515 - lr: 1.4150e-05\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 1.4324810480858029e-05.\n",
      "Epoch 10/20\n",
      "536/536 [==============================] - 1740s 3s/step - loss: 56.2406 - accuracy: 0.9532 - lr: 1.4325e-05\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1.44995032916002e-05.\n",
      "Epoch 11/20\n",
      "536/536 [==============================] - 1771s 3s/step - loss: 56.2369 - accuracy: 0.9542 - lr: 1.4500e-05\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1.4674196102342371e-05.\n",
      "Epoch 12/20\n",
      "536/536 [==============================] - 1670s 3s/step - loss: 56.2333 - accuracy: 0.9555 - lr: 1.4674e-05\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.4848888913084543e-05.\n",
      "Epoch 13/20\n",
      "536/536 [==============================] - 1663s 3s/step - loss: 56.2294 - accuracy: 0.9572 - lr: 1.4849e-05\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.5023581723826714e-05.\n",
      "Epoch 14/20\n",
      "536/536 [==============================] - 1672s 3s/step - loss: 56.2259 - accuracy: 0.9579 - lr: 1.5024e-05\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5198274534568885e-05.\n",
      "Epoch 15/20\n",
      "536/536 [==============================] - 1673s 3s/step - loss: 56.2231 - accuracy: 0.9590 - lr: 1.5198e-05\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.5372967345311056e-05.\n",
      "Epoch 16/20\n",
      "536/536 [==============================] - 1667s 3s/step - loss: 56.2196 - accuracy: 0.9603 - lr: 1.5373e-05\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.5547660156053228e-05.\n",
      "Epoch 17/20\n",
      "536/536 [==============================] - 1673s 3s/step - loss: 56.2163 - accuracy: 0.9613 - lr: 1.5548e-05\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.57223529667954e-05.\n",
      "Epoch 18/20\n",
      "536/536 [==============================] - 1676s 3s/step - loss: 56.2127 - accuracy: 0.9629 - lr: 1.5722e-05\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.589704577753757e-05.\n",
      "Epoch 19/20\n",
      "536/536 [==============================] - 1676s 3s/step - loss: 56.2097 - accuracy: 0.9637 - lr: 1.5897e-05\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.607173858827974e-05.\n",
      "Epoch 20/20\n",
      "536/536 [==============================] - 1678s 3s/step - loss: 56.2064 - accuracy: 0.9650 - lr: 1.6072e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f458e7cc350>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lrate has to be passed in model fit inside a list of callbacks\n",
    "training = True\n",
    "model.fit([X_train, Y_in_train], Yoh_train, epochs=20, batch_size=32, callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1.100564707675678e-05.\n",
      "Epoch 1/5\n",
      "536/536 [==============================] - 1640s 3s/step - loss: 56.2965 - accuracy: 0.9373 - lr: 1.1006e-05\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.118033988749895e-05.\n",
      "Epoch 2/5\n",
      "536/536 [==============================] - 1639s 3s/step - loss: 56.2924 - accuracy: 0.9383 - lr: 1.1180e-05\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1.1355032698241122e-05.\n",
      "Epoch 3/5\n",
      "536/536 [==============================] - 1641s 3s/step - loss: 56.2883 - accuracy: 0.9396 - lr: 1.1355e-05\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 1.1529725508983293e-05.\n",
      "Epoch 4/5\n",
      "536/536 [==============================] - 1642s 3s/step - loss: 56.2846 - accuracy: 0.9402 - lr: 1.1530e-05\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 1.1704418319725463e-05.\n",
      "Epoch 5/5\n",
      "536/536 [==============================] - 1640s 3s/step - loss: 56.2798 - accuracy: 0.9417 - lr: 1.1704e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef40217710>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train, Y_in_train], Yoh_train, epochs=20, batch_size=32, callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.keras.metrics.CategoricalAccuracy.update_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAccuracy(tf.keras.metrics.CategoricalAccuracy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MaskedAccuracy, self).__init__(self, *args, **kwargs)\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super(MaskedAccuracy, self).update_state(y_true, y_pred)\n",
    "    \n",
    "    def reset_states(self):\n",
    "        super(MaskedAccuracy, self).reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling _positional_encoding.\n",
      "Calling _positional_encoding.\n",
      "Calling EncoderUnit.\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n",
      "Calling DecoderUnit.\n",
      "Calling MultiheadAttention.\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "(None, 7, 7)\n",
      "Calling MultiheadAttention.\n",
      "Calling FeedforwardUnit.\n",
      "134/134 [==============================] - 105s 785ms/step - loss: 56.3462 - accuracy: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[56.34616470336914, 0.8978829979896545]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test, Y_in_test], Yoh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join([inv_total_vocab[w] for w in X_train[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[inv_total_vocab[w] for w in Y_in_train[106]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_total_vocab[np.argmax(w)] for w in Yoh_train[106]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_total_vocab[w] for w in Y_in_test[1197]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 1012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 505 # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 1301 # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 1197 # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([X_test[start_index:start_index+1], Y_in_test[start_index:start_index+1]])\n",
    "prediction.shape\n",
    "output = np.array(list(np.argmax(w) for w in prediction[0]))\n",
    "output_read = [inv_total_vocab[np.argmax(w)] for w in prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr`aw thāwitrhin 'ama' tr`ānit<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print(''.join([inv_total_vocab[w] for w in X_test[start_index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traw\n",
      "ta:na\n",
      "'ama'\n",
      "tra:nit\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "print(output_read[1])\n",
    "i = 2\n",
    "while True:\n",
    "    prediction = model.predict([X_test[start_index:start_index+1], output.reshape((1,7))])\n",
    "    output = np.array(list(np.argmax(w) for w in prediction[0]))\n",
    "    output_read = [inv_total_vocab[np.argmax(w)] for w in prediction[0]]\n",
    "    print(output_read[i])\n",
    "    i += 1\n",
    "    if '<end>' in output_read:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', ',', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([X_train[95:96], output.reshape((1,7))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.array(list(np.argmax(w) for w in prediction[0]))\n",
    "output_read = [inv_total_vocab[np.argmax(w)] for w in prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', ',', \"'ama'\", '<pad>', '<pad>', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([X_train[102:103], output.reshape((1,7))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINISHED ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "# 93 epochs so far\n",
    "# problem: this is taking the original sequence as input to the output, \n",
    "#  rather than the previous time points of the output!\n",
    "#training = True\n",
    "\n",
    "# stop! only use this when FINISHED training!\n",
    "if training == True:\n",
    "    model.save_weights('weights_2.keras')\n",
    "    print(\"Saved.\")\n",
    "else:\n",
    "    print(\"Training is false!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STARTING ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights.\n"
     ]
    }
   ],
   "source": [
    "# stop! only use this when starting training!\n",
    "if training == False:\n",
    "    model.load_weights('weights_2.keras')\n",
    "    print(\"Loaded weights.\")\n",
    "else:\n",
    "    print(\"Training is true!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
